\chapter{Literature Review}\label{ch: literature review}

\section{Decoding}\label{sec: decoding-lit-rev}
\begin{itemize}
    \item Chubb2021\cite{Chubb2021-se} discusses tensor networking decoding of 2D local codes. These are under phenomenological noise models for bit-flip, phase-flip and depolarizing noise. This is the results to replicate by mid October
    \item  BSV2014\cite{Bravyi2014-kw} discusses the equivalence between maximum Likelihood decoding and tensor network contraction.
    \item
\end{itemize}


\section{Tensor Networks}\label{sec: tensor-networks-lit-rev}
\begin{itemize}
    \item Quantum Lego\cite{Cao2022-xf} considers building quantum error correcting codes as tensor networks.
    \item TN Codes\cite{Farrelly2021-da} introduces tensor network stabilizer codes.
    \item Hand-Wavy\cite{Bridgeman2017-rk} is an introduction to Tensor Networks.
\end{itemize}

\section{Noise Models and Simulations}\label{sec: noise-models-lit-rev}
\begin{itemize}
    \item Stim\cite{Gidney2021-am} is probably the backend we are going to be using to generate noise data.
    \item
\end{itemize}

\section{Stat Mech}\label{sec: stat-mech-lit-rev}
\begin{itemize}
    \item DLKP's\cite{Dennis2002-wo} paper on Topological Quantum Memory is one of the first paper to discuss the statistical physics of error recovery.
    \item Infamous-Chubb-Flammia\cite{Chubb2018-gh} generalises the proof for the statistical mechanical mapping from DLKP\cite{Dennis2002-wo} for independent noise to weakly correlated noise. It also discusses the link between Maximum Likelihood Decoding and Tensor Network Contraction.
    \item
\end{itemize}
